"""
ğŸ—„ï¸ Smart Cache Manager - Multi-Tier Caching System
Created by: Rafael & AI Assistant (Phase 2)
Version: 1.0 - Production Ready

××˜×¨×”:
×× ×”×œ Cache ×—×›× ×©××§×˜×™×Ÿ ××ª ××¡×¤×¨ ×”×§×¨×™××•×ª ×œ-API-Sports ×-500 ×œ-100 ×œ×™×•×
×¢×œ ×™×“×™ ×©××™×¨×ª × ×ª×•× ×™× ×¢× TTL (Time To Live) ××©×ª× ×” ×œ×¤×™ ×¡×•×’ ×”× ×ª×•×Ÿ.

×¢×§×¨×•× ×•×ª:
âœ… Thread-safe / Async-safe (asyncio.Lock)
âœ… TTL per key (×œ× global)
âœ… Metadata tracking (timestamp, hits, last_access)
âœ… Auto cleanup (××—×™×§×ª ×¢×¨×›×™× ×™×©× ×™×)
âœ… Statistics (hit ratio, memory usage)

×œ× Redis - In-memory ×–×” ××¡×¤×™×§ ×œ×©×œ×‘ ×”×–×”.
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Tuple
from dataclasses import dataclass, field
import json

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """
    ğŸ“¦ ×¢×¨×š ×‘×•×“×“ ×‘-Cache

    Attributes:
        data: ×”× ×ª×•× ×™× ×¢×¦×× (dict, list, str, etc.)
        timestamp: ××ª×™ × ×©××¨
        ttl: Time To Live ×‘×©× ×™×•×ª
        hits: ×›××” ×¤×¢××™× × ×§×¨×
        last_access: ×’×™×©×” ××—×¨×•× ×”
    """
    data: Any
    timestamp: datetime
    ttl: int  # seconds
    hits: int = 0
    last_access: datetime = field(default_factory=datetime.now)

    def is_expired(self) -> bool:
        """×‘×“×•×§ ×× ×”×¢×¨×š ×¤×’ ×ª×•×§×£"""
        age = (datetime.now() - self.timestamp).total_seconds()
        return age > self.ttl

    def age_seconds(self) -> float:
        """×›××” ×©× ×™×•×ª ×¢×‘×¨×• ×××– ×”×©××™×¨×”"""
        return (datetime.now() - self.timestamp).total_seconds()

    def to_dict(self) -> dict:
        """×”××¨×” ×œ-dict ×œ××˜×¨×•×ª × ×™×¤×•×™ ×‘××’×™×"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "ttl": self.ttl,
            "hits": self.hits,
            "last_access": self.last_access.isoformat(),
            "age_seconds": self.age_seconds(),
            "expired": self.is_expired()
        }


class CacheManager:
    """
    ğŸ—„ï¸ ×× ×”×œ Cache ×—×›× ×¢× TTL ××©×ª× ×”

    Features:
    âœ… Multi-tier TTL (6h, 3h, 24h, 30min)
    âœ… Thread-safe with asyncio.Lock
    âœ… Auto cleanup every 100 accesses
    âœ… Detailed statistics
    âœ… Memory-efficient (max 1000 entries)

    Usage:
        cache = CacheManager()

        # Set
        await cache.set("standings_39", data, ttl=21600)  # 6 hours

        # Get
        value = await cache.get("standings_39", ttl=21600)
        if value:
            print("Cache HIT!")
        else:
            print("Cache MISS - fetch from API")
    """

    def __init__(self, max_entries: int = 1000):
        """
        ××ª×—×•×œ ×× ×”×œ Cache

        Args:
            max_entries: ××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ ×¢×¨×›×™× (×‘×¨×™×¨×ª ××—×“×œ: 1000)
        """
        self._cache: Dict[str, CacheEntry] = {}
        self._lock = asyncio.Lock()
        self._max_entries = max_entries

        # Statistics
        self._total_gets = 0
        self._total_sets = 0
        self._cache_hits = 0
        self._cache_misses = 0
        self._cleanup_count = 0
        self._auto_cleanup_interval = 100  # cleanup every 100 accesses

        logger.info(f"ğŸš€ CacheManager initialized (max_entries={max_entries})")

    async def get(self, key: str, ttl: Optional[int] = None) -> Optional[Any]:
        """
        ğŸ” ×§×‘×œ ×¢×¨×š ××”-Cache (×× ×§×™×™× ×•×œ× ×¤×’ ×ª×•×§×£)

        Args:
            key: ××¤×ª×— ×™×™×—×•×“×™ (×œ×“×•×’××”: "standings_39_2024")
            ttl: TTL ×œ×‘×“×™×§×” (×× ×œ× ×¡×•×¤×§, ×œ× ×‘×•×“×§ TTL)

        Returns:
            ×”× ×ª×•× ×™× ×× ×§×™×™××™× ×•×ª×§×¤×™×, ××—×¨×ª None
        """
        async with self._lock:
            self._total_gets += 1

            # Auto cleanup every N accesses
            if self._total_gets % self._auto_cleanup_interval == 0:
                await self._cleanup_expired()

            if key not in self._cache:
                self._cache_misses += 1
                logger.debug(f"âŒ Cache MISS: {key}")
                return None

            entry = self._cache[key]

            # Check if expired
            if entry.is_expired():
                self._cache_misses += 1
                logger.debug(f"â° Cache EXPIRED: {key} (age={entry.age_seconds():.0f}s, ttl={entry.ttl}s)")
                del self._cache[key]
                return None

            # Cache HIT!
            self._cache_hits += 1
            entry.hits += 1
            entry.last_access = datetime.now()

            logger.info(f"âœ… Cache HIT: {key} (age={entry.age_seconds():.0f}s, hits={entry.hits})")
            return entry.data

    async def set(self, key: str, data: Any, ttl: int) -> None:
        """
        ğŸ’¾ ×©××•×¨ ×¢×¨×š ×‘-Cache

        Args:
            key: ××¤×ª×— ×™×™×—×•×“×™
            data: × ×ª×•× ×™× ×œ×©××™×¨×”
            ttl: Time To Live ×‘×©× ×™×•×ª
        """
        async with self._lock:
            self._total_sets += 1

            # Check memory limit
            if len(self._cache) >= self._max_entries:
                await self._cleanup_oldest()

            entry = CacheEntry(
                data=data,
                timestamp=datetime.now(),
                ttl=ttl
            )

            self._cache[key] = entry
            logger.info(f"ğŸ’¾ Cache SET: {key} (ttl={ttl}s, size={len(self._cache)})")

    async def delete(self, key: str) -> bool:
        """
        ğŸ—‘ï¸ ××—×§ ×¢×¨×š ×¡×¤×¦×™×¤×™

        Returns:
            True ×× × ××—×§, False ×× ×œ× ×§×™×™×
        """
        async with self._lock:
            if key in self._cache:
                del self._cache[key]
                logger.info(f"ğŸ—‘ï¸ Cache DELETE: {key}")
                return True
            return False

    async def clear(self) -> int:
        """
        ğŸ§¹ × ×§×” ××ª ×›×œ ×”-Cache

        Returns:
            ××¡×¤×¨ ×”×¢×¨×›×™× ×©× ××—×§×•
        """
        async with self._lock:
            count = len(self._cache)
            self._cache.clear()
            logger.info(f"ğŸ§¹ Cache CLEARED: {count} entries removed")
            return count

    async def _cleanup_expired(self) -> int:
        """
        ğŸ§¼ × ×™×§×•×™ ××•×˜×•××˜×™ ×©×œ ×¢×¨×›×™× ×©×¤×’ ×ª×•×§×¤×

        Returns:
            ××¡×¤×¨ ×”×¢×¨×›×™× ×©× ××—×§×•
        """
        expired_keys = [
            key for key, entry in self._cache.items()
            if entry.is_expired()
        ]

        for key in expired_keys:
            del self._cache[key]

        if expired_keys:
            self._cleanup_count += 1
            logger.info(f"ğŸ§¼ Auto cleanup #{self._cleanup_count}: {len(expired_keys)} expired entries removed")

        return len(expired_keys)

    async def _cleanup_oldest(self, count: int = 100) -> int:
        """
        ğŸ—‘ï¸ ××—×§ ××ª ×”×¢×¨×›×™× ×”×›×™ ×™×©× ×™× (LRU - Least Recently Used)

        Args:
            count: ×›××” ×¢×¨×›×™× ×œ××—×•×§

        Returns:
            ××¡×¤×¨ ×”×¢×¨×›×™× ×©× ××—×§×•
        """
        if not self._cache:
            return 0

        # Sort by last_access
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: x[1].last_access
        )

        # Delete oldest
        deleted = 0
        for key, _ in sorted_entries[:count]:
            del self._cache[key]
            deleted += 1

        logger.warning(f"ğŸ—‘ï¸ Memory cleanup: {deleted} oldest entries removed (was {len(self._cache) + deleted})")
        return deleted

    def get_stats(self) -> dict:
        """
        ğŸ“Š ×§×‘×œ ×¡×˜×˜×™×¡×˜×™×§×•×ª ××¤×•×¨×˜×•×ª

        Returns:
            dict ×¢× ×›×œ ×”× ×ª×•× ×™× ×”×¡×˜×˜×™×¡×˜×™×™×
        """
        total_requests = self._cache_hits + self._cache_misses
        hit_ratio = (self._cache_hits / total_requests * 100) if total_requests > 0 else 0

        # Calculate memory usage (rough estimate)
        memory_mb = sum(
            len(json.dumps(entry.data)) if isinstance(entry.data, (dict, list)) else 100
            for entry in self._cache.values()
        ) / (1024 * 1024)

        return {
            "cache_size": len(self._cache),
            "max_entries": self._max_entries,
            "memory_usage_mb": round(memory_mb, 2),
            "total_gets": self._total_gets,
            "total_sets": self._total_sets,
            "cache_hits": self._cache_hits,
            "cache_misses": self._cache_misses,
            "hit_ratio": f"{hit_ratio:.1f}%",
            "cleanup_count": self._cleanup_count,
            "status": "ğŸŸ¢ Healthy" if hit_ratio > 60 else "ğŸŸ¡ Low efficiency"
        }

    def get_all_keys(self) -> list:
        """
        ğŸ”‘ ×§×‘×œ ×¨×©×™××ª ×›×œ ×”××¤×ª×—×•×ª ×‘-Cache

        Returns:
            list ×©×œ ××¤×ª×—×•×ª
        """
        return list(self._cache.keys())

    def get_entry_metadata(self, key: str) -> Optional[dict]:
        """
        ğŸ” ×§×‘×œ metadata ×©×œ ×¢×¨×š ×¡×¤×¦×™×¤×™

        Args:
            key: ××¤×ª×— ×œ×‘×“×™×§×”

        Returns:
            dict ×¢× metadata ××• None ×× ×œ× ×§×™×™×
        """
        if key not in self._cache:
            return None

        entry = self._cache[key]
        return {
            "key": key,
            **entry.to_dict()
        }


# ğŸŒ Global instance (singleton pattern)
# ×©×™××•×©: from cache_manager import cache_manager
cache_manager = CacheManager(max_entries=1000)


# ğŸ¯ Helper: TTL Constants (×œ×©×™××•×© ×§×œ)
class CacheTTL:
    """×§×‘×•×¢×™× ×œ×–×× ×™ TTL × ×¤×•×¦×™×"""
    LIVE_MATCH = 30  # 30 seconds
    MATCH_DETAILS = 1800  # 30 minutes
    LAST_5_MATCHES = 10800  # 3 hours
    STANDINGS = 21600  # 6 hours
    H2H = 86400  # 24 hours
    STATIC = 604800  # 7 days


if __name__ == "__main__":
    """
    ğŸ§ª ×‘×“×™×§×•×ª ×™×—×™×“×”
    """
    async def test_cache():
        print("ğŸ§ª Testing CacheManager...\n")

        cache = CacheManager(max_entries=5)

        # Test 1: Set and Get
        print("Test 1: Set and Get")
        await cache.set("test_key", {"value": 123}, ttl=5)
        result = await cache.get("test_key")
        assert result == {"value": 123}, "Failed: data mismatch"
        print("âœ… Passed\n")

        # Test 2: Expiration
        print("Test 2: Expiration")
        await cache.set("expire_key", {"value": 456}, ttl=1)
        await asyncio.sleep(2)
        result = await cache.get("expire_key")
        assert result is None, "Failed: should be expired"
        print("âœ… Passed\n")

        # Test 3: Cache HIT
        print("Test 3: Cache HIT")
        await cache.set("hit_key", {"value": 789}, ttl=10)
        result1 = await cache.get("hit_key")
        result2 = await cache.get("hit_key")
        assert result1 == result2, "Failed: inconsistent data"
        stats = cache.get_stats()
        assert stats["cache_hits"] >= 2, "Failed: hits not recorded"
        print(f"âœ… Passed (hits={stats['cache_hits']})\n")

        # Test 4: Statistics
        print("Test 4: Statistics")
        stats = cache.get_stats()
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        assert "hit_ratio" in stats, "Failed: missing hit_ratio"
        print("âœ… Passed\n")

        print("ğŸ‰ All tests passed!")

    # Run tests
    asyncio.run(test_cache())
