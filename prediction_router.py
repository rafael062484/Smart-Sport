"""
ğŸ§  Prediction Router - AI-Powered Match Predictions

××˜×¤×œ ×‘×›×œ endpoints ×©×œ ×ª×—×–×™×•×ª AI:
- POST /api/predict        â†’ ×ª×—×–×™×ª ×™×—×™×“×” ××¤×•×¨×˜×ª
- POST /api/predict/batch  â†’ ×ª×—×–×™×•×ª ××¨×•×‘×•×ª
- POST /api/predict/compareâ†’ ×”×©×•×•××ª ×§×‘×•×¦×•×ª

Created: 2026-01-24
Author: Claude Code & Rafael
"""

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import logging

# ×™×¦×™×¨×ª Router
router = APIRouter(tags=["AI Predictions"])

# ×”×’×“×¨×ª ×œ×•×’×¨
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PredictRequest(BaseModel):
    """ğŸ“Š ×‘×§×©×ª ×ª×—×–×™×ª ×™×—×™×“×”"""
    home: str = Field(..., description="×§×‘×•×¦×” ×‘×™×ª×™×ª", min_length=2)
    away: str = Field(..., description="×§×‘×•×¦×” ××•×¨×—×ª", min_length=2)
    league: str = Field(default="General", description="×œ×™×’×”")
    depth: str = Field(default="standard", pattern="^(quick|standard|deep|expert)$")
    match_date: Optional[str] = Field(None, description="×ª××¨×™×š ×”××©×—×§ (YYYY-MM-DD)")


class BatchPredictRequest(BaseModel):
    """ğŸ“Š ×‘×§×©×ª ×ª×—×–×™×•×ª ××¨×•×‘×•×ª"""
    matches: List[Dict[str, str]] = Field(..., description="×¨×©×™××ª ××©×—×§×™×")
    depth: str = Field(default="quick", pattern="^(quick|standard|deep|expert)$")


class CompareRequest(BaseModel):
    """ğŸ“Š ×‘×§×©×ª ×”×©×•×•××”"""
    team1: str = Field(..., description="×§×‘×•×¦×” 1")
    team2: str = Field(..., description="×§×‘×•×¦×” 2")
    league: str = Field(default="General", description="×œ×™×’×”")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PREDICTION ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/api/predict")
async def predict_match(request: PredictRequest):
    """
    ğŸ¯ ×ª×—×–×™×ª AI ××¤×•×¨×˜×ª ×œ××©×—×§ ×‘×•×“×“

    ××§×‘×œ:
    - ×§×‘×•×¦×” ×‘×™×ª×™×ª ×•××•×¨×—×ª
    - ×œ×™×’×” (××•×¤×¦×™×•× ×œ×™)
    - ×¨××ª ×¢×•××§ (quick/standard/deep/expert)
    - ×ª××¨×™×š ××©×—×§ (××•×¤×¦×™×•× ×œ×™)

    ××—×–×™×¨:
    - ×ª×—×–×™×ª ××¤×•×¨×˜×ª ×¢× × ×™×ª×•×—
    - ××—×•×–×™ × ×™×¦×—×•×Ÿ
    - ×ª×•×¦××” ×¦×¤×•×™×”
    - × ×™××•×§×™×
    """
    try:
        from backend.app import AI_ENGINE_LOADED, get_match_prediction, logger as app_logger

        if not AI_ENGINE_LOADED:
            return {
                "success": False,
                "error": "AI Engine not available",
                "fallback_prediction": {
                    "home_team": request.home,
                    "away_team": request.away,
                    "predicted_result": "Demo Mode - AI disabled",
                    "confidence": 0,
                    "analysis": "×× ×•×¢ ×”-AI ×œ× ×–××™×Ÿ ×›×¨×’×¢. ×× × × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨ ××• ×¤× ×” ×œ×ª××™×›×”."
                }
            }

        # ×§×¨×™××” ×œ×× ×•×¢ ×”-AI
        result = await get_match_prediction(
            home_team=request.home,
            away_team=request.away,
            league=request.league,
            analysis_depth=request.depth.upper(),
            match_date=request.match_date
        )

        if result and result.get("success"):
            return {
                "success": True,
                "prediction": result.get("prediction", {}),
                "timestamp": result.get("timestamp"),
                "engine_version": result.get("engine_version")
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Failed to generate prediction")
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×™×¦×™×¨×ª ×ª×—×–×™×ª: {str(e)}")


@router.post("/api/predict/batch")
async def predict_batch(request: BatchPredictRequest):
    """
    ğŸ¯ ×ª×—×–×™×•×ª AI ×œ×›××” ××©×—×§×™× ×‘×•-×–×× ×™×ª

    ××§×‘×œ:
    - ×¨×©×™××ª ××©×—×§×™× (×¢×“ 10)
    - ×¨××ª ×¢×•××§

    ××—×–×™×¨:
    - ×¨×©×™××ª ×ª×—×–×™×•×ª
    - ×¡×™×›×•×
    """
    try:
        from backend.app import AI_ENGINE_LOADED, analyze_batch, logger as app_logger

        if not AI_ENGINE_LOADED:
            # Fallback ×œ××¦×‘ ×“××•
            demo_predictions = []
            for match in request.matches[:4]:  # ××§×¡×™××•× 4
                demo_predictions.append({
                    "success": False,
                    "home_team": match.get("home", "Unknown"),
                    "away_team": match.get("away", "Unknown"),
                    "error": "AI Engine not available - Demo mode"
                })

            return {
                "success": False,
                "predictions": demo_predictions,
                "total": len(demo_predictions),
                "message": "×× ×•×¢ ×”-AI ×œ× ×–××™×Ÿ"
            }

        # ×”×’×‘×œ×” ×œ-10 ××©×—×§×™×
        matches_to_analyze = request.matches[:10]

        # ×§×¨×™××” ×œ×× ×•×¢ ×”-AI
        results = await analyze_batch(
            matches=matches_to_analyze,
            analysis_depth=request.depth.upper()
        )

        if results:
            return {
                "success": True,
                "predictions": results,
                "total": len(results),
                "depth": request.depth
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to generate batch predictions")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Batch prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×ª×—×–×™×•×ª ××¨×•×‘×•×ª: {str(e)}")


@router.post("/api/predict/compare")
async def compare_teams(request: CompareRequest):
    """
    âš–ï¸ ×”×©×•×•××ª ×©×ª×™ ×§×‘×•×¦×•×ª

    ××§×‘×œ:
    - ×©×ª×™ ×§×‘×•×¦×•×ª
    - ×œ×™×’×”

    ××—×–×™×¨:
    - ×”×©×•×•××” ××¤×•×¨×˜×ª
    - ×¡×˜×˜×™×¡×˜×™×§×•×ª
    - × ×™×ª×•×— ×›×•×—×•×ª
    """
    try:
        from backend.app import AI_ENGINE_LOADED, get_comparison, logger as app_logger

        if not AI_ENGINE_LOADED:
            return {
                "success": False,
                "error": "AI Engine not available",
                "message": "×× ×•×¢ ×”-AI ×œ× ×–××™×Ÿ ×›×¨×’×¢"
            }

        # ×§×¨×™××” ×œ×× ×•×¢ ×”-AI
        result = await get_comparison(
            team1=request.team1,
            team2=request.team2,
            league=request.league
        )

        if result:
            return {
                "success": True,
                "comparison": result
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to generate comparison")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Comparison error: {e}")
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×”×©×•×•××”: {str(e)}")
